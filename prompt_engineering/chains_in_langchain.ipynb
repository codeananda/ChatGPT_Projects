{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Based on the given text \"Hallo, ich bin 25 Jahre alt,\" it can be classified as CEFR level A1.'}, {'text': 'A2'}, {'text': 'A2'}]\n",
      "apply time taken: 2.79 seconds\n",
      "\n",
      "[{'text': 'Based on the given text \"Hallo, ich bin 25 Jahre alt,\" it can be classified as CEFR level A1.'}, {'text': 'A2'}, {'text': 'A2'}]\n",
      "aapply time taken: 2.05 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    'Classify the text based on the Common European Framework of Reference '\n",
    "    'for Languages (CEFR). Give a single value: {text}',\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "texts = [\n",
    "    {'text': 'Hallo, ich bin 25 Jahre alt.'},\n",
    "    {'text': 'Wie geht es dir?'},\n",
    "    {'text': 'In meiner Freizeit, spiele ich gerne Fussball.'}\n",
    "]\n",
    "\n",
    "start = time()\n",
    "res_a = chain.apply(texts)\n",
    "print(res_a)\n",
    "print(f\"apply time taken: {time() - start:.2f} seconds\")\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "res_aa = await chain.aapply(texts)\n",
    "print(res_aa)\n",
    "print(f\"aapply time taken: {time() - start:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    ")\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                   Product                                             Review\n0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n4  Milk Frother Handheld\\n   I loved this product. But they only seem to l...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Queen Size Sheet Set</td>\n      <td>I ordered a king size set. My only criticism w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Waterproof Phone Pouch</td>\n      <td>I loved the waterproof sac, although the openi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Luxury Air Mattress</td>\n      <td>This mattress had a small hole in the top of i...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pillows Insert</td>\n      <td>This is the best throw pillow fillers on Amazo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Milk Frother Handheld\\n</td>\n      <td>I loved this product. But they only seem to l...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/product_reviews.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Langy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classify Level of Text and Provide Reason"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"level\": string  // The CEFR level of the text, e.g. A1, B2, etc.\n",
      "\t\"reason\": string  // The reason for the classification\n",
      "}\n",
      "```\n",
      "{'level': 'A2', 'reason': 'The text demonstrates a basic understanding of the language with simple sentence structures and limited vocabulary. The use of present tense and basic expressions indicate a beginner level of proficiency.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "cefr_template =\"\"\"Classify the text based on the Common European Framework of Reference\n",
    "for Languages (CEFR), provide a reason for your answer.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    " \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(cefr_template)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define output schema\n",
    "level_schema = ResponseSchema(name=\"level\",\n",
    "                             description=\"The CEFR level of the text, e.g. A1, B2, etc.\")\n",
    "reason_schema = ResponseSchema(name=\"reason\",\n",
    "                                    description=\"The reason for the classification\")\n",
    "\n",
    "response_schemas = [level_schema, reason_schema]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "text = \"\"\"Hallo, ich heisse Adam. Ich habe 25 Jahre alt. Ich wohne in England seit 15 Jahren aber ich wuerde gerne irgendwo anders wohnen. Ich liebe es zu reisen. Meiner Meinung nach, ist man wirklich am leben, wenn man reist.\"\"\"\n",
    "\n",
    "# messages = prompt.format(text=text, format_instructions=format_instructions)\n",
    "\n",
    "# messages = [\n",
    "#     {'text': text, 'format_instructions': format_instructions}\n",
    "# ]\n",
    "# response = chain.apply(messages)\n",
    "\n",
    "messages = {'text': text, 'format_instructions': format_instructions}\n",
    "response = chain.run(messages)\n",
    "\n",
    "result = output_parser.parse(response)\n",
    "print(result)\n",
    "type(result)\n",
    "# response[0]['text']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reason\": \"The text can be classified as A1 level based on the following reasons:\\n\\n1. Vocabulary: The text uses basic vocabulary such as 'Hallo' (Hello), 'ich' (I), 'heisse' (am called), 'alt' (old), 'und' (and), 'jungere' (younger), and 'Schwester' (sister). These are common words that are typically learned at the beginner level.\\n\\n2. Sentence Structure: The text consists of simple sentences with basic grammatical structures. For example, 'Ich habe 25 Jahre alt' (I am 25 years old) and 'fuenf jungere Schwester' (five younger sisters). The sentence structure is straightforward and does not involve complex grammar.\\n\\n3. Lack of Complex Expressions: The text does not contain any complex expressions or idiomatic phrases. It uses simple and direct language to convey basic information about the speaker.\\n\\nBased on these factors, the text aligns with the A1 level of the CEFR.\", \"level\": \"A1\"}"
     ]
    },
    {
     "data": {
      "text/plain": "ReasonLevel(reason=\"The text can be classified as A1 level based on the following reasons:\\n\\n1. Vocabulary: The text uses basic vocabulary such as 'Hallo' (Hello), 'ich' (I), 'heisse' (am called), 'alt' (old), 'und' (and), 'jungere' (younger), and 'Schwester' (sister). These are common words that are typically learned at the beginner level.\\n\\n2. Sentence Structure: The text consists of simple sentences with basic grammatical structures. For example, 'Ich habe 25 Jahre alt' (I am 25 years old) and 'fuenf jungere Schwester' (five younger sisters). The sentence structure is straightforward and does not involve complex grammar.\\n\\n3. Lack of Complex Expressions: The text does not contain any complex expressions or idiomatic phrases. It uses simple and direct language to convey basic information about the speaker.\\n\\nBased on these factors, the text aligns with the A1 level of the CEFR.\", level='A1')"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hallo, ich heisse Adam. Ich habe 25 Jahre alt und fuenf jungere Schwester.'\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "template_reason_level =\"\"\"Classify the text based on the Common European Framework of Reference\n",
    "for Languages (CEFR), provide detailed reasons for your answer.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    " \"\"\"\n",
    "\n",
    "class ReasonLevel(BaseModel):\n",
    "    reason: str = Field(description=\"Detailed reasons for the classification\")\n",
    "    level: str = Field(description=\"The CEFR level of the text, e.g. A1, B2, etc.\")\n",
    "\n",
    "parser_reason_level = PydanticOutputParser(pydantic_object=ReasonLevel)\n",
    "\n",
    "prompt_template_reason_level = ChatPromptTemplate(\n",
    "    messages=[HumanMessagePromptTemplate.from_template(template_reason_level)],\n",
    "    input_variables=['text'],\n",
    "    partial_variables={'format_instructions': parser_reason_level.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain_reason_level = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template_reason_level,\n",
    "    output_key='reason_level'\n",
    ")\n",
    "\n",
    "output_reason_level = chain_reason_level({'text': text})\n",
    "results_reason_level = parser_reason_level.parse(output_reason_level['reason_level'])\n",
    "results_reason_level"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is helping the human improve their foreign language writing skills. The human provides texts written in a foreign language and the AI corrects the spelling and grammar of the texts and provides detailed reasons for each correction.\n",
      "\n",
      "The AI keeps in in mind spelling, grammar, naturalness (how much it sounds like a native speaker), correct capitalisation,\n",
      "correct placement of commas or other punctuation and anything else necessary for correct writing.\n",
      "\n",
      "The AI only provides corrections for words/phrases that have changed. If the original text is the same as the corrected text, then the AI does not provide a correction.\n",
      "\n",
      "The AI knows that each sentence may contain multiple errors and provides corrections for all errors in the sentence.\n",
      "It also knows that some sentences will not contain any errors and does not provide corrections for those sentences.\n",
      "\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hallo, ich heisse Adam. Ich habe 25 Jahre alt.\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich heiße Adam. Ich bin 25 Jahre alt.\n",
      "\n",
      "Reasons:\n",
      "1. Corrected spelling of 'heisse' to 'heiße' because 'heiße' is the correct spelling in German\n",
      "2. Corrected 'alt' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\n",
      "Human: Ich bin 25 Jahre alt\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich bin 25 Jahre alt.\n",
      "\n",
      "Reasons:\n",
      "1. Added full stop to the end of the sentence because it is a complete sentence.\n",
      "Human: Ich habe eine Katze. Sie ist schwarz und klein.\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich habe eine Katze. Sie ist schwarz und klein.\n",
      "\n",
      "Reasons:\n",
      "1. No corrections needed. The text is grammatically correct and natural.\n",
      "Human: Ich wohne auf England fuer 15 Jahren.\n",
      "AI: Let's think step by step\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is helping the human improve their foreign language writing skills. The human provides texts written in a foreign language and the AI corrects the spelling and grammar of the texts and provides detailed reasons for each correction.\n",
      "\n",
      "The AI keeps in in mind spelling, grammar, naturalness (how much it sounds like a native speaker), correct capitalisation,\n",
      "correct placement of commas or other punctuation and anything else necessary for correct writing.\n",
      "\n",
      "The AI only provides corrections for words/phrases that have changed. If the original text is the same as the corrected text, then the AI does not provide a correction.\n",
      "\n",
      "The AI knows that each sentence may contain multiple errors and provides corrections for all errors in the sentence.\n",
      "It also knows that some sentences will not contain any errors and does not provide corrections for those sentences.\n",
      "\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hallo, ich heisse Adam. Ich habe 25 Jahre alt.\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich heiße Adam. Ich bin 25 Jahre alt.\n",
      "\n",
      "Reasons:\n",
      "1. Corrected spelling of 'heisse' to 'heiße' because 'heiße' is the correct spelling in German\n",
      "2. Corrected 'alt' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\n",
      "Human: Ich bin 25 Jahre alt\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich bin 25 Jahre alt.\n",
      "\n",
      "Reasons:\n",
      "1. Added full stop to the end of the sentence because it is a complete sentence.\n",
      "Human: Ich habe eine Katze. Sie ist schwarz und klein.\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich habe eine Katze. Sie ist schwarz und klein.\n",
      "\n",
      "Reasons:\n",
      "1. No corrections needed. The text is grammatically correct and natural.\n",
      "Human: Ich wohne auf England fuer 15 Jahren.\n",
      "AI: Corrected text: Ich wohne in England seit 15 Jahren.\n",
      "\n",
      "Reasons:\n",
      "1. Corrected 'auf' to 'in' because 'in' is the correct preposition to use when talking about living in a country.\n",
      "2. Corrected 'fuer' to 'seit' because 'seit' is the correct preposition to use when talking about the duration of time.\n",
      "3. Corrected '15' to 'fünfzehn' because numbers in German are written as words, not digits.\n",
      "4. Added 'Jahren' after '15' to indicate the duration of time.\n",
      "Human: „Tom! Tom! Wo sind du?“\n",
      "Keine Antwort.\n",
      "„Wo ist dem bloß? Wenn ich ihm finde,\n",
      "werde ich...“\n",
      "Tante Polly schaut unter das Bett. Dann\n",
      "öffnet sie die Haustür und schaut in den\n",
      "Garten.\n",
      "AI: Let's think step by step\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is helping the human improve their foreign language writing skills. The human provides texts written in a foreign language and the AI corrects the spelling and grammar of the texts and provides detailed reasons for each correction.\n",
      "\n",
      "The AI keeps in in mind spelling, grammar, naturalness (how much it sounds like a native speaker), correct capitalisation,\n",
      "correct placement of commas or other punctuation and anything else necessary for correct writing.\n",
      "\n",
      "The AI only provides corrections for words/phrases that have changed. If the original text is the same as the corrected text, then the AI does not provide a correction.\n",
      "\n",
      "The AI knows that each sentence may contain multiple errors and provides corrections for all errors in the sentence.\n",
      "It also knows that some sentences will not contain any errors and does not provide corrections for those sentences.\n",
      "\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hallo, ich heisse Adam. Ich habe 25 Jahre alt.\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich heiße Adam. Ich bin 25 Jahre alt.\n",
      "\n",
      "Reasons:\n",
      "1. Corrected spelling of 'heisse' to 'heiße' because 'heiße' is the correct spelling in German\n",
      "2. Corrected 'alt' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\n",
      "Human: Ich bin 25 Jahre alt\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich bin 25 Jahre alt.\n",
      "\n",
      "Reasons:\n",
      "1. Added full stop to the end of the sentence because it is a complete sentence.\n",
      "Human: Ich habe eine Katze. Sie ist schwarz und klein.\n",
      "AI: Let's think step by step\n",
      "Corrected text: Ich habe eine Katze. Sie ist schwarz und klein.\n",
      "\n",
      "Reasons:\n",
      "1. No corrections needed. The text is grammatically correct and natural.\n",
      "Human: Ich wohne auf England fuer 15 Jahren.\n",
      "AI: Corrected text: Ich wohne in England seit 15 Jahren.\n",
      "\n",
      "Reasons:\n",
      "1. Corrected 'auf' to 'in' because 'in' is the correct preposition to use when talking about living in a country.\n",
      "2. Corrected 'fuer' to 'seit' because 'seit' is the correct preposition to use when talking about the duration of time.\n",
      "3. Corrected '15' to 'fünfzehn' because numbers in German are written as words, not digits.\n",
      "4. Added 'Jahren' after '15' to indicate the duration of time.\n",
      "Human: „Tom! Tom! Wo sind du?“\n",
      "Keine Antwort.\n",
      "„Wo ist dem bloß? Wenn ich ihm finde,\n",
      "werde ich...“\n",
      "Tante Polly schaut unter das Bett. Dann\n",
      "öffnet sie die Haustür und schaut in den\n",
      "Garten.\n",
      "AI: Corrected text: \"Tom! Tom! Wo bist du?\"\n",
      "Keine Antwort.\n",
      "\"Wo ist er bloß? Wenn ich ihn finde,\n",
      "werde ich...\"\n",
      "Tante Polly schaut unter das Bett. Dann\n",
      "öffnet sie die Haustür und schaut in den\n",
      "Garten.\n",
      "\n",
      "Reasons:\n",
      "1. Corrected 'sind' to 'bist' because 'bist' is the correct form of the verb 'sein' (to be) to use with the pronoun 'du' (you).\n",
      "2. Corrected 'dem' to 'ihn' because 'ihn' is the correct pronoun to use when referring to a person (in this case, Tom).\n",
      "3. Removed the quotation marks around the entire text because they are not necessary.\n",
      "4. No other corrections needed. The text is grammatically correct and natural.\n",
      "Human: Eltern klagen, dass ihre Kinder ihnen nicht gehorchen, Streit den Alltag bestimmt. Lehrer klagen über freche bis gewalttätige Schüler und, das fehlenden Interesse der Eltern an der Schule nach. Sie fühlen sich mit der Aufgabe überfordert, gleichzeitig Erziehungs- und Bildungsarbeit leisten zu mussen.\n",
      "AI: Let's think step by step\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Corrected text: Eltern klagen, dass ihre Kinder ihnen nicht gehorchen, Streit den Alltag bestimmt. Lehrer klagen über freche bis gewalttätige Schüler und das fehlende Interesse der Eltern an der Schule. Sie fühlen sich mit der Aufgabe überfordert, gleichzeitig Erziehungs- und Bildungsarbeit leisten zu müssen.\\n\\nReasons:\\n1. Removed the comma after 'Schüler' because it is not necessary.\\n2. Corrected 'das fehlenden' to 'das fehlende' because 'fehlende' is the correct form of the adjective to use with 'Interesse' (interest).\\n3. Removed 'nach' after 'Schule' because it is not necessary.\\n4. Corrected 'mussen' to 'müssen' because 'müssen' is the correct form of the verb to use in this sentence.\""
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationTokenBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, streaming=True)\n",
    "DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is helping the human improve their foreign language writing skills. The human provides texts written in a foreign language and the AI corrects the spelling and grammar of the texts and provides detailed reasons for each correction.\n",
    "\n",
    "The AI keeps in in mind spelling, grammar, naturalness (how much it sounds like a native speaker), correct capitalisation,\n",
    "correct placement of commas or other punctuation and anything else necessary for correct writing.\n",
    "\n",
    "The AI only provides corrections for words/phrases that have changed. If the original text is the same as the corrected text, then the AI does not provide a correction.\n",
    "\n",
    "The AI knows that each sentence may contain multiple errors and provides corrections for all errors in the sentence.\n",
    "It also knows that some sentences will not contain any errors and does not provide corrections for those sentences.\n",
    "\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI: Let's think step by step\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=DEFAULT_TEMPLATE)\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=4000)\n",
    "# system_prompt = \"\"\"I want you to help me improve my foreign language writing skills.\n",
    "# I will give you texts in a foreign language. Please correct the spelling and grammar\n",
    "# of them.\n",
    "#\n",
    "# Keep in mind spelling,\n",
    "# grammar, naturalness (how much it sounds like a native speaker), correct capitalisation,\n",
    "# correct placement of commas or other punctuation and anything else necessary for correct\n",
    "# writing.\n",
    "#\n",
    "# Provide a detailed reason for each correction.\n",
    "#\n",
    "# Do not do anything else other than correct the text I've just passed in and providing explanations.\n",
    "#\n",
    "# Please reply with \"Ok!\" to show you have understood. The next message I send after that will be\n",
    "# the first text you need to correct.\n",
    "# \"\"\"\n",
    "#\n",
    "# memory.save_context(\n",
    "#     {'input': system_prompt},\n",
    "#     {'output': 'Ok!'}\n",
    "# )\n",
    "\n",
    "input_1 = 'Hallo, ich heisse Adam. Ich habe 25 Jahre alt.'\n",
    "output_1 = \"\"\"Let's think step by step\n",
    "Corrected text: Ich heiße Adam. Ich bin 25 Jahre alt.\n",
    "\n",
    "Reasons:\n",
    "1. Corrected spelling of 'heisse' to 'heiße' because 'heiße' is the correct spelling in German\n",
    "2. Corrected 'alt' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\"\"\"\n",
    "memory.save_context(\n",
    "    {'input': input_1},\n",
    "     {'output': output_1}\n",
    ")\n",
    "\n",
    "input_2 = 'Ich bin 25 Jahre alt'\n",
    "output_2 = \"\"\"Let's think step by step\n",
    "Corrected text: Ich bin 25 Jahre alt.\n",
    "\n",
    "Reasons:\n",
    "1. Added full stop to the end of the sentence because it is a complete sentence.\"\"\"\n",
    "memory.save_context(\n",
    "    {'input': input_2},\n",
    "     {'output': output_2}\n",
    ")\n",
    "\n",
    "input_3 = \"Ich habe eine Katze. Sie ist schwarz und klein.\"\n",
    "output_3 = \"\"\"Let's think step by step\n",
    "Corrected text: Ich habe eine Katze. Sie ist schwarz und klein.\n",
    "\n",
    "Reasons:\n",
    "1. No corrections needed. The text is grammatically correct and natural.\"\"\"\n",
    "\n",
    "memory.save_context(\n",
    "    {'input': input_3},\n",
    "     {'output': output_3}\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True,\n",
    "    prompt=PROMPT,\n",
    ")\n",
    "\n",
    "conversation.predict(input='Ich wohne auf England fuer 15 Jahren.')\n",
    "\n",
    "tom = \"\"\"„Tom! Tom! Wo sind du?“\n",
    "Keine Antwort.\n",
    "„Wo ist dem bloß? Wenn ich ihm finde,\n",
    "werde ich...“\n",
    "Tante Polly schaut unter das Bett. Dann\n",
    "öffnet sie die Haustür und schaut in den\n",
    "Garten.\"\"\"\n",
    "x = conversation.predict(input=tom)\n",
    "\n",
    "eltern = \"\"\"Eltern klagen, dass ihre Kinder ihnen nicht gehorchen, Streit den Alltag bestimmt. Lehrer klagen über freche bis gewalttätige Schüler und, das fehlenden Interesse der Eltern an der Schule nach. Sie fühlen sich mit der Aufgabe überfordert, gleichzeitig Erziehungs- und Bildungsarbeit leisten zu mussen.\"\"\"\n",
    "\n",
    "x = conversation.predict(input=eltern)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'AI: First, let\\'s correct the sentence \"Wo sind du?\" to \"Wo bist du?\" because \"bist\" is the correct verb form to use with the pronoun \"du\" in German.\\n\\nNext, let\\'s correct the sentence \"Wo ist dem bloß?\" to \"Wo ist er bloß?\" because \"er\" is the correct pronoun to use when referring to a male person.\\n\\nFinally, let\\'s correct the sentence \"Tante Polly schautet\" to \"Tante Polly schaut\" because \"schautet\" is not a correct verb form in German. The correct form is \"schaut.\"\\n\\nPutting it all together, the corrected text is:\\n\"Tom! Tom! Wo bist du?\"\\nKeine Antwort.\\n\"Wo ist er bloß? Wenn ich ihn finde,\\nwerde ich...\"\\nTante Polly schaut unter das Bett. Dann\\nöffnet sie die Haustür und schaut in den\\nGarten.'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'text': 'Hallo, ich heisse Adam. Ich habe 25 Jahre alt und fuenf jungere Schwester.',\n 'corrected_text': '{\"corrected_text\": \"Hallo, ich heiße Adam. Ich bin 25 Jahre alt und habe fünf jüngere Schwestern.\", \"reasons\": [\"Corrected spelling of \\'heisse\\' to \\'heiße\\' because \\'heiße\\' is the correct spelling in German.\", \"Corrected \\'alt\\' to \\'bin\\' because \\'bin\\' is the correct verb to use when stating one\\'s age in German.\", \"Corrected \\'jungere\\' to \\'jüngere\\' because \\'jüngere\\' is the correct spelling of \\'younger\\' in German.\", \"Changed \\'Schwester\\' to \\'Schwestern\\' because \\'Schwestern\\' is the plural form of \\'Schwester\\'.\"] }'}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_correct = \"\"\"\"I want you to help me improve my foreign language writing skills.\n",
    "Here is a text I've written in a foreign language. Please correct the spelling and grammar\n",
    "of the text.\n",
    "\n",
    "Keep in mind spelling,\n",
    "grammar, naturalness (how much it sounds like a native speaker), correct capitalisation,\n",
    "correct placement of commas or other punctuation and anything else necessary for correct\n",
    "writing. Provide a detailed reason for each correction.\n",
    "\n",
    "Text: {text}\n",
    "\"\"\"\n",
    "template_correct_with_format = template_correct + \"\"\"\\n\\n{format_instructions}\"\"\"\n",
    "\n",
    "class CorrectedText(BaseModel):\n",
    "    corrected_text: str = Field(description=\"The corrected text\")\n",
    "    reasons: List[str] = Field(description=\"Detailed reasons for each correction\")\n",
    "\n",
    "parser_corrected_text = PydanticOutputParser(pydantic_object=CorrectedText)\n",
    "\n",
    "prompt_template_correct = ChatPromptTemplate(\n",
    "    messages=[HumanMessagePromptTemplate.from_template(template_correct)],\n",
    "    input_variables=['text'],\n",
    "    partial_variables={'format_instructions': parser_corrected_text.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain_correct = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template_correct,\n",
    "    output_key='corrected_text'\n",
    ")\n",
    "\n",
    "output_correct = chain_correct({'text': text})\n",
    "results_correct = parser_corrected_text.parse(output_correct['corrected_text'])\n",
    "results_correct\n",
    "\n",
    "output_correct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "{'text': 'Hallo, ich heisse Adam. Ich habe 25 Jahre alt und fuenf jungere Schwester.',\n 'corrected_text': '{\"corrected_text\": \"Hallo, ich heiße Adam. Ich bin 25 Jahre alt und habe fünf jüngere Schwestern.\", \"reasons\": [\"Corrected spelling of \\'heisse\\' to \\'heiße\\' because \\'heiße\\' is the correct spelling in German.\", \"Corrected \\'alt\\' to \\'bin\\' because \\'bin\\' is the correct verb to use when stating one\\'s age in German.\", \"Corrected \\'fuenf\\' to \\'fünf\\' because \\'fünf\\' is the correct spelling of the number \\'five\\' in German.\", \"Corrected \\'Schwester\\' to \\'Schwestern\\' because \\'Schwestern\\' is the correct plural form of \\'Schwester\\' in German.\"]}'}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_correct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'text': 'Hallo, ich heisse Adam. Ich habe 25 Jahre alt und fuenf jungere Schwester.',\n 'corrected_text': 'Hallo, ich heiße Adam. Ich bin 25 Jahre alt und habe fünf jüngere Schwestern.',\n 'reasons': [\"Corrected spelling of 'heisse' to 'heiße' because 'heiße' is the correct spelling in German.\",\n  \"Corrected 'alt' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\",\n  \"Corrected 'fuenf' to 'fünf' because 'fünf' is the correct spelling of the number 'five' in German.\",\n  \"Corrected 'Schwester' to 'Schwestern' because 'Schwestern' is the correct plural form of 'Schwester' in German.\"],\n 'check': '\"reasons\": [\"Corrected spelling of \\'heisse\\' to \\'heiße\\' because \\'ss\\' can be combined to\\n     \\'ß\\' in German.\", \"Corrected \\'habe\\' to \\'bin\\' because \\'bin\\' is the correct verb to use when stating one\\'s age in German.\", \"Corrected spelling of \\'fuenf\\' to \\'fünf\\' because \\'fünf\\' is the correct spelling of the number \\'five\\' in German.\", \"Corrected \\'Schwester\\' to \\'Schwestern\\' because \\'Schwestern\\' is the correct plural form of \\'Schwester\\' in German.\"]'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_check = \"\"\"Here is some input text in a foreign language, a corrected\n",
    "version of the text and detailed reasons for the corrections.\n",
    "\n",
    "For each reason, check if that is actually what has happened in the text.\n",
    "\n",
    "Check the corrected text and reasons for each correction.\n",
    "Do all the reasons make sense? Are the reasons themselves correct?\n",
    "If not, please update the list of reasons and provide a reason for each update.\n",
    "\n",
    "Each section is delimited by ####\n",
    "\n",
    "Input text: ####{text}####\n",
    "Corrected text: ####{corrected_text}####\n",
    "Reasons: ####{reasons}####\n",
    "\"\"\"\n",
    "\n",
    "template_check = HumanMessagePromptTemplate.from_template(template_check)\n",
    "example_human = template_check.format_messages(**{\n",
    "    'text': 'Ich heisse Adam. Ich habe 25 Jahre alt.',\n",
    "    'corrected_text': 'Ich heiße Adam. Ich bin 25 Jahre alt.',\n",
    "    'reasons': [\"Corrected spelling of 'heisse' to 'heiße' because 'heiße' is the correct spelling in German.\", \"Corrected 'alt' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\"]\n",
    "})[0]\n",
    "example_ai = AIMessagePromptTemplate.from_template(\n",
    "    '''\"reasons\": [\"Corrected spelling of 'heisse' to 'heiße' because 'ss' can be combined to\n",
    "     'ß' in German.\", \"Corrected 'habe' to 'bin' because 'bin' is the correct verb to use when stating one's age in German.\"]'''\n",
    ")\n",
    "\n",
    "prompt_template_check = ChatPromptTemplate(\n",
    "    messages=[example_human, example_ai, template_check],\n",
    "    input_variables=['text', 'corrected_text', 'reasons'],\n",
    "    # partial_variables={'format_instructions': parser_corrected_text.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain_check = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template_check,\n",
    "    output_key='check'\n",
    ")\n",
    "chain_check({\n",
    "    'text': text,\n",
    "    'corrected_text': results_correct.corrected_text,\n",
    "    'reasons': results_correct.reasons\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='Here is some input text in a foreign language, a corrected\\nversion of the text and detailed reasons for the corrections.\\n\\nFor each reason, check if that is actually what has happened in the text.\\n\\nCheck the corrected text and reasons for each correction.\\nDo all the reasons make sense? Are the reasons themselves correct?\\nIf not, please update the list of reasons and provide a reason for each update.\\n\\nEach section is delimited by ####\\n\\nInput text: ####Ich heisse Adam. Ich habe 25 Jahre alt.####\\nCorrected text: ####Ich heiße Adam. Ich bin 25 Jahre alt.####\\nReasons: ####[\"Corrected spelling of \\'heisse\\' to \\'heiße\\' because \\'heiße\\' is the correct spelling in German.\", \"Corrected \\'alt\\' to \\'bin\\' because \\'bin\\' is the correct verb to use when stating one\\'s age in German.\"]####\\n', additional_kwargs={}, example=False)]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_human"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='\"reasons\": [\"Corrected spelling of \\'heisse\\' to \\'heiße\\' because \\'ss\\' can be combined to\\n     \\'ß\\' in German.\", \"Corrected \\'habe\\' to \\'bin\\' because \\'bin\\' is the correct verb to use when stating one\\'s age in German.\"]', template_format='f-string', validate_template=True), additional_kwargs={})"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_ai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='Here is some input text in a foreign language, a corrected\\nversion of the text and detailed reasons for the corrections.\\n\\nCheck the corrected text and reasons for each correction.\\nDo all the reasons make sense? Are the reasons themselves correct?\\nIf not, please update the list of reasons and provide a reason for each update.\\n\\nEach section is delimited by ####\\n\\nInput text: ####Hallo, ich heisse Adam. Ich habe 25 Jahre alt und fuenf jungere Schwester.####\\nCorrected text: ####Hallo, ich heiße Adam. Ich bin 25 Jahre alt und habe fünf jüngere Schwestern.####\\nReasons: ####[\"Corrected spelling of \\'heisse\\' to \\'heiße\\' because \\'heiße\\' is the correct spelling in German.\", \"Corrected \\'alt\\' to \\'bin\\' because \\'bin\\' is the correct verb to use when stating one\\'s age in German.\", \"Corrected \\'fuenf\\' to \\'fünf\\' because \\'fünf\\' is the correct spelling of the number \\'five\\' in German.\", \"Corrected \\'Schwester\\' to \\'Schwestern\\' because \\'Schwestern\\' is the correct plural form of \\'Schwester\\' in German.\"]####\\n', additional_kwargs={}, example=False)]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = HumanMessagePromptTemplate.from_template(template_check)\n",
    "x.format_messages(**{\n",
    "    'text': text,\n",
    "    'corrected_text': results_correct.corrected_text,\n",
    "    'reasons': results_correct.reasons\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"The reason for the classification\", \"type\": \"string\"}, \"level\": {\"title\": \"Level\", \"description\": \"The CEFR level of the text, e.g. A1, B2, etc.\", \"type\": \"string\"}}, \"required\": [\"reason\", \"level\"]}\\n```'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_reason_level.get_format_instructions()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "'A1'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correct Grammar and Spelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"corrected_text\": string  // The corrected text\n",
      "\t\"reasons\": string  // The reasons for the corrections\n",
      "}\n",
      "```\n",
      "{'corrected_text': 'Hallo, ich heiße Adam. Ich bin 25 Jahre alt. Ich wohne seit 15 Jahren in England, aber ich würde gerne irgendwo anders wohnen. Ich liebe es zu reisen. Meiner Meinung nach ist man wirklich am Leben, wenn man reist.', 'reasons': \"1. Corrected the spelling of 'heisse' to 'heiße' because it should have an 'ß' instead of 'ss'.\\n2. Changed 'habe' to 'bin' because '25 Jahre alt' is a state of being, not possession.\\n3. Added a comma after 'England' to separate the clauses.\\n4. Removed the space before 'wuerde' to correct the spelling.\\n5. Removed the space before 'Meiner' to correct the sentence structure.\\n6. Removed the comma after 'nach' to improve the flow of the sentence.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "gram_spell_template =\"\"\"Correct the grammar and spelling of the text. Provide a reason for\n",
    "each correction.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    " \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(gram_spell_template)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define output schema\n",
    "corrected_schema = ResponseSchema(name=\"corrected_text\",\n",
    "                                    description=\"The corrected text\")\n",
    "reasons_schema = ResponseSchema(name=\"reasons\",\n",
    "                                description=\"The reasons for the corrections\")\n",
    "\n",
    "\n",
    "response_schemas = [corrected_schema, reasons_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "text = \"\"\"Hallo, ich heisse Adam. Ich habe 25 Jahre alt. Ich wohne in England seit 15 Jahren aber ich wuerde gerne irgendwo anders wohnen. Ich liebe es zu reisen. Meiner Meinung nach, ist man wirklich am leben, wenn man reist.\"\"\"\n",
    "\n",
    "messages = {\n",
    "    'text': text,\n",
    "    'format_instructions': format_instructions\n",
    "}\n",
    "response = chain.run(messages)\n",
    "# response\n",
    "\n",
    "result = output_parser.parse(response)\n",
    "print(result)\n",
    "type(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Based on the provided text \"Hallo, ich bin 25 Jahre alt,\" it can be classified as A1 level according to the Common European Framework of Reference for Languages (CEFR). \\n\\nThe reason for this classification is that the text consists of simple and basic vocabulary and sentence structures. It includes a greeting (\"Hallo\") and a simple statement about the person\\'s age (\"ich bin 25 Jahre alt\"). A1 level is the beginner level, where learners can understand and use familiar everyday expressions and basic phrases to communicate simple and immediate needs.'}, {'text': 'According to the Common European Framework of Reference for Languages (CEFR), the text \"Wie geht es dir?\" can be classified as A1 level. \\n\\nThe reason for this classification is that the text consists of a simple question in German, asking \"How are you?\" This type of question is commonly taught at the beginner level, where learners are introduced to basic greetings and expressions. At the A1 level, learners are expected to understand and use simple everyday phrases and expressions, as well as be able to interact in a simple way, provided the other person speaks slowly and clearly.'}, {'text': 'Based on the given text, it can be classified as A1 level according to the Common European Framework of Reference for Languages (CEFR). \\n\\nReason: The text consists of simple and basic vocabulary and sentence structures. It talks about a personal preference in a straightforward manner without any complex language usage. This level is characterized by the ability to understand and use familiar everyday expressions and very basic phrases related to personal information and needs.'}]\n",
      "apply time taken: 9.38 seconds\n",
      "\n",
      "[{'text': 'Based on the provided text \"Hallo, ich bin 25 Jahre alt,\" it can be classified as A1 level according to the Common European Framework of Reference for Languages (CEFR). \\n\\nThe reason for this classification is that the text consists of simple and basic vocabulary and sentence structures. It includes a greeting (\"Hallo\") and a simple statement about the person\\'s age (\"ich bin 25 Jahre alt\"). A1 level is the beginner level, where learners can understand and use familiar everyday expressions and basic phrases to communicate simple and immediate needs.'}, {'text': 'According to the Common European Framework of Reference for Languages (CEFR), the text \"Wie geht es dir?\" can be classified as A1 level. \\n\\nThe reason for this classification is that the text is a simple and common question in German, which is typically taught at the beginner level. A1 level learners are expected to be able to understand and use basic phrases and expressions related to personal information, daily routines, and simple interactions. \"Wie geht es dir?\" translates to \"How are you?\" in English, and it is one of the first phrases that beginners learn when studying German.'}, {'text': 'Based on the given text, it can be classified as A1 level according to the Common European Framework of Reference for Languages (CEFR). \\n\\nReason: The text consists of simple and basic vocabulary and sentence structures. It talks about a personal preference in a straightforward manner without any complex language usage. This level is characterized by the ability to understand and use familiar everyday expressions and very basic phrases related to personal information and needs.'}]\n",
      "aapply time taken: 3.56 seconds\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    {'text': 'Hallo, ich bin 25 Jahre alt.'},\n",
    "    {'text': 'Wie geht es dir?'},\n",
    "    {'text': 'In meiner Freizeit spiele ich gerne Fussball.'}\n",
    "]\n",
    "start = time()\n",
    "res_a = chain.apply(texts)\n",
    "print(res_a)\n",
    "print(f\"apply time taken: {time() - start:.2f} seconds\")\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "res_aa = await chain.aapply(texts)\n",
    "print(res_aa)\n",
    "print(f\"aapply time taken: {time() - start:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'text'}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\chatgpt\\lib\\site-packages\\langchain\\chains\\llm.py:213\u001B[0m, in \u001B[0;36mLLMChain.predict\u001B[1;34m(self, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, callbacks: Callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    199\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m \n\u001B[0;32m    201\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\chatgpt\\lib\\site-packages\\langchain\\chains\\base.py:123\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    108\u001B[0m     inputs: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Any],\n\u001B[0;32m    109\u001B[0m     return_only_outputs: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    110\u001B[0m     callbacks: Callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    111\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m    112\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Run the logic of this chain and add to output if desired.\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \n\u001B[0;32m    114\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    121\u001B[0m \n\u001B[0;32m    122\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 123\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprep_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    124\u001B[0m     callback_manager \u001B[38;5;241m=\u001B[39m CallbackManager\u001B[38;5;241m.\u001B[39mconfigure(\n\u001B[0;32m    125\u001B[0m         callbacks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose\n\u001B[0;32m    126\u001B[0m     )\n\u001B[0;32m    127\u001B[0m     new_arg_supported \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\chatgpt\\lib\\site-packages\\langchain\\chains\\base.py:216\u001B[0m, in \u001B[0;36mChain.prep_inputs\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    214\u001B[0m     external_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory\u001B[38;5;241m.\u001B[39mload_memory_variables(inputs)\n\u001B[0;32m    215\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mexternal_context)\n\u001B[1;32m--> 216\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\chatgpt\\lib\\site-packages\\langchain\\chains\\base.py:83\u001B[0m, in \u001B[0;36mChain._validate_inputs\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     81\u001B[0m missing_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_keys)\u001B[38;5;241m.\u001B[39mdifference(inputs)\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing_keys:\n\u001B[1;32m---> 83\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing some input keys: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_keys\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Missing some input keys: {'text'}"
     ]
    }
   ],
   "source": [
    "chain.predict(a=texts[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LLMChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Queen Size Sheet Set, Generated name: \"Royal Dreams Linens\" or \"Regal Comfort Bedding\"\n",
      "Product: Waterproof Phone Pouch, Generated name: Aquashield\n",
      "Product: Luxury Air Mattress, Generated name: 1. Opulent Rest\n",
      "2. LuxeSlumber\n",
      "3. Supreme Sleep\n",
      "4. Elite Air Mattress Co.\n",
      "5. DreamSerenity\n",
      "6. LuxAir Mattress\n",
      "7. PlushDreams\n",
      "8. PrestigeSleep\n",
      "9. RegalAir Mattress\n",
      "10. SereneSlumber\n",
      "Product: Pillows Insert, Generated name: The Cushion Corner\n",
      "Product: Milk Frother Handheld\n",
      ", Generated name: \"Milk Frother Plus\" or \"FrothMaster\"\n"
     ]
    }
   ],
   "source": [
    "# High temp -> more creative names\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    'What is the best name to describe a company that sells {product}?',\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "for product in df.Product.iloc[:5]:\n",
    "    company_name_idea = chain.run(product)\n",
    "    print(f\"Product: {product}, Generated name: {company_name_idea}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "LLMResult(generations=[[ChatGeneration(text='RoyalComfort Beddings', generation_info=None, message=AIMessage(content='RoyalComfort Beddings', additional_kwargs={}, example=False))], [ChatGeneration(text='AquaGuard Phone Accessories', generation_info=None, message=AIMessage(content='AquaGuard Phone Accessories', additional_kwargs={}, example=False))], [ChatGeneration(text='OpulentRest', generation_info=None, message=AIMessage(content='OpulentRest', additional_kwargs={}, example=False))], [ChatGeneration(text='PillowPerfect', generation_info=None, message=AIMessage(content='PillowPerfect', additional_kwargs={}, example=False))], [ChatGeneration(text='FrothMaster', generation_info=None, message=AIMessage(content='FrothMaster', additional_kwargs={}, example=False))]], llm_output={'token_usage': {'prompt_tokens': 116, 'completion_tokens': 19, 'total_tokens': 135}, 'model_name': 'gpt-3.5-turbo'})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also generate multiple results at once like this\n",
    "products = list(df.Product.iloc[:5])\n",
    "products = [{'product': product} for product in products]\n",
    "chain.generate(products)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: you can use OpenAI via your Azure deployment like so\n",
    "\n",
    "```python\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "deployment_name=\"your-azure-deployment\",\n",
    "model_name=\"text-davinci-003\"\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SimpleSequentialChain\n",
    "\n",
    "The simplest form of sequential chains, where each step has a singular input/output, and the output of one step is the input to the next."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mRoyal Comfort Beddings\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mRoyal Comfort Beddings is a luxury bedding brand offering top-quality, stylish bedding sets and accessories for a blissful sleep experience.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mAquaGuard Phone Protection\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mAquaGuard Phone Protection offers high-quality waterproof cases and screen protectors to ensure maximum protection for your valuable smartphones.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mOpulent Rest\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mOpulent Rest offers luxurious and high-quality bedding products that provide the ultimate comfort and relaxation for a restful night's sleep.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mPillowPro\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mPillowPro offers premium and customizable pillows designed for optimal comfort and support, ensuring a restful night's sleep.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mFrothMaster\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mFrothMaster is a leading manufacturer of high-quality milk frothers, delivering perfectly frothed milk for your favorite coffee creations.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    'What is the best name to describe a company that sells {product}?',\n",
    ")\n",
    "first_chain = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    'Write a 20 word description for the following company: {company_name}',\n",
    ")\n",
    "second_chain = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "overall_simple_chain = SimpleSequentialChain(\n",
    "    chains=[first_chain, second_chain],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "for product in df.Product.iloc[:5]:\n",
    "    overall_simple_chain.run(product)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SequentialChain\n",
    "\n",
    "A more general form of sequential chains, allowing for multiple inputs/outputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    'Translate the following review to English: {review}',\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key='english_review')\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    'Summarize the following review in 1 sentence: {english_review}',\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key='summary')\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    'What language is the following review: {review}'\n",
    ")\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key='language')\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    'What a follow up response to the following summary in the specified'\n",
    "    'language: Summary: {summary}\\n\\n Language: {language}'\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key='follow_up_response')\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=['review'],\n",
    "    output_variables=['english_review', 'summary', 'follow_up_response'],\n",
    "    verbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
